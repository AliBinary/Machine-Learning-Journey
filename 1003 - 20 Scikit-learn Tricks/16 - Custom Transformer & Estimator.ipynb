{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1 align=\"center\">Scikit-Learn Tips</h1>\n",
    "    <h3 align=\"center\">Tip 16 : Creating custom scikit-learn Transformers</h3>\n",
    "    <h4 align=\"center\"><a href=\"https://github.com/AliBinary\">Ali Ghanbari</a></h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Creating a Custom Transformer\n",
    "In scikit-learn, Transformers are objects that transform a dataset into a new one to prepare the dataset for predictive modeling, e.g., scaling numeric values, one-hot encoding categoricals, etc.\n",
    "\n",
    "While scikit-learn has many Transformers, it's often helpful to create our own. This post will look at three ways to make your own Custom Transformers: Creating a Custom Transformer from scratch, using the FunctionTransformer, and subclassing an existing Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This method defines a custom transformer by inheriting BaseEstimator and TransformerMixin classes of Scikit-Learn.\n",
    "*‘BaseEstimator’ class of Scikit-Learn enables hyperparameter tuning by adding the ‘set_params’ and ‘get_params’ methods. \n",
    "* While, ‘TransformerMixin’ class adds the ‘fit_transform’ method without explicitly defining it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Data Import\n",
    "data = pd.DataFrame(load_iris()['data'],columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,factor=1.5):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def outlier_detector(self,X,y=None):\n",
    "        X = pd.Series(X).copy()\n",
    "        q1 = X.quantile(0.25)\n",
    "        q3 = X.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        self.lower_bound.append(q1 - (self.factor * iqr))\n",
    "        self.upper_bound.append(q3 + (self.factor * iqr))\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.lower_bound = []\n",
    "        self.upper_bound = []\n",
    "        X.apply(self.outlier_detector)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        for i in range(X.shape[1]):\n",
    "            x = X.iloc[:, i].copy()\n",
    "            x[(x < self.lower_bound[i]) | (x > self.upper_bound[i])] = np.nan\n",
    "            X.iloc[:, i] = x\n",
    "        return X\n",
    "    \n",
    "outlier_remover = OutlierRemover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'col1':[100,200,300,999],'col2':[0,0,1,2],'col3':[-10,0,1,2]})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_remover.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_remover.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_remover.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_remover_100 = OutlierRemover(factor=100)\n",
    "outlier_remover_100.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind=\"box\",subplots=True,figsize=(15,5),title=\"Data with Outliers\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_remover = OutlierRemover()\n",
    "\n",
    "#ColumnTransformer to remove outliers\n",
    "ct = ColumnTransformer(transformers=[['outlier_remover',OutlierRemover(),list(range(data.shape[1]))]],remainder='passthrough')\n",
    "\n",
    "#iris data after outlier removal\n",
    "data_without_outliers = pd.DataFrame(ct.fit_transform(data),columns=data.columns)\n",
    "\n",
    "#iris data box plot after outlier removal\n",
    "data_without_outliers.plot(kind=\"box\",subplots=True,figsize=(15,5),title=\"Data without Outliers\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 outliers are removed from SepalWidthCm, other columns stayed the same as they have no outliers.\n",
    "data_without_outliers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers removed from sepal width (cm)\n",
    "list(data.loc[data_without_outliers.isnull().sum(axis=1)>0,'SepalWidthCm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "y = load_iris()['target'].copy()\n",
    "\n",
    "#Pipeline with outlier remover, imputer and regressor\n",
    "pipeline = Pipeline(steps=[['outlier_removal',ct],['imputer',SimpleImputer()],['regressor',LogisticRegression(max_iter=1000)]]) \n",
    "\n",
    "param_grid = {'outlier_removal__outlier_remover__factor':[0,1,2,3,4],\n",
    "              'imputer__strategy':['mean','median','most_frequent'],\n",
    "              'regressor__C':[0.01,0.1,1,10,100]}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "gs.fit(X,y)\n",
    "\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. https://sklearn-template.readthedocs.io/en/latest/user_guide.html\n",
    "2. https://www.andrewvillazon.com/custom-scikit-learn-transformers/\n",
    "3. https://amueller.github.io/aml/05-advanced-topics/14-custom-estimators.html\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
