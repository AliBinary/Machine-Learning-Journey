{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "df = pd.read_csv(\"./insurance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Phase 1: The First Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "\n",
    "# Do the column names make sense? Does the data in the rows look correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the min/max values (for spotting outliers)? Are the mean and median (50%) far apart (which indicates skew)?\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total duplicated rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Phase 2: Univariate Analysis (One Variable at a Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of this data? Is it symmetric (a \"normal\" bell curve)? Is it skewed? Does it have one peak (unimodal) or multiple peaks (multimodal)?\n",
    "sns.histplot(df['expenses'], kde=True, bins=30)\n",
    "plt.title('Distribution of Medical Charges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there data points far outside the \"whiskers\"? These are outliers.\n",
    "sns.boxplot(x=df['bmi'])\n",
    "plt.title('Box Plot of BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the classes balanced (e.g., 50/50 smokers/non-smokers) or imbalanced (e.g., 90/10)?\n",
    "\n",
    "print(df['smoker'].value_counts())\n",
    "\n",
    "print(df['smoker'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['region'])\n",
    "plt.title('Count of Patients by Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Phase 3: Bivariate Analysis (Two Variables at a Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a relationship? Is it linear (a straight line)? Is it positive (goes up) or negative (goes down)?\n",
    "sns.scatterplot(x=df['age'], y=df['expenses'])\n",
    "plt.title('Age vs. Medical expenses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['age'].corr(df['expenses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the distribution of the numerical variable change for each category?\n",
    "sns.boxplot(x=df['smoker'], y=df['expenses'])\n",
    "plt.title('Smoker Status vs. Medical expenses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['region'], hue=df['smoker'])\n",
    "plt.title('Smoker Distribution by Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Phase 4: Multivariate Analysis (3+ Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are most correlated with the target (expenses)? Are any of your features highly correlated with each other (this is multicollinearity and can be a problem)?\n",
    "\n",
    "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "corr_matrix = numerical_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the relationship between age and expenses depend on whether the person is a smoker? (This is an interaction effect).\n",
    "\n",
    "sns.scatterplot(x=df['age'], y=df['expenses'], hue=df['smoker'])\n",
    "plt.title('Age vs. expenses (Colored by Smoker)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Phase 5: Summarize Findings & Plan Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goal: Turn your insights into a concrete plan for preprocessing and feature engineering.\n",
    "\n",
    "Example Findings Summary:\n",
    "\n",
    "    Target: expenses is heavily right-skewed.\n",
    "\n",
    "    Missing Data: The dataset is clean, no missing values to impute.\n",
    "\n",
    "    Categorical: sex, smoker, and region all need to be one-hot encoded.\n",
    "\n",
    "    Key Predictors: smoker is the strongest predictor by far. age and bmi are also positively correlated with expenses.\n",
    "\n",
    "    Interactions: The effect of age on expenses is much stronger for smokers.\n",
    "\n",
    "Resulting Action Plan:\n",
    "\n",
    "    Preprocessing: Log-transform expenses (i.e., df['log_expenses'] = np.log(df['expenses'])) and use this new column as your target y.\n",
    "\n",
    "    Preprocessing: One-hot encode sex, smoker, and region.\n",
    "\n",
    "    Feature Engineering: Create an interaction term, such as age * smoker_status or bmi * smoker_status, \n",
    "    as these relationships are clearly not simple.\n",
    "\n",
    "    Model Selection: Since the smoker effect is so strong, a simple LinearRegression will likely do well, \n",
    "    but a DecisionTree or RandomForest will be able to capture the non-linear interactions automatically.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dropping: Remove the entire row or column if it has missing data. This is okay if you have a huge dataset and only a few missing rows, \n",
    "but it's generally wasteful.\n",
    "\n",
    "Imputation: Fill in the missing values. This is the preferred method.\n",
    "\n",
    "    Numerical: Fill with the mean or median (median is better if the data is skewed).\n",
    "\n",
    "    Categorical: Fill with the mode (the most frequent category).\n",
    "\"\"\"\n",
    "print(df.isnull().sum())\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df['bmi'] = num_imputer.fit_transform(df[['bmi']])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[['region']] = cat_imputer.fit_transform(df[['region']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We use One-Hot Encoding. This technique creates new binary (0 or 1) columns for each category.\n",
    "\n",
    "sex: \"male\", \"female\" → Becomes sex_male (1 if male, 0 if female).\n",
    "\n",
    "smoker: \"yes\", \"no\" → Becomes smoker_yes (1 if smoker, 0 if not).\n",
    "\n",
    "After running this, your sex column is gone, replaced by sex_male. Your smoker column is gone, replaced by smoker_yes. \n",
    "Your region column is gone, replaced by region_northwest, \n",
    "region_southeast, and region_southwest. (The fourth one, northeast, is represented when all the others are 0).\n",
    "\"\"\"\n",
    "df_processed = df.copy()\n",
    "\n",
    "df_processed = pd.get_dummies(df_processed, \n",
    "                              columns=['sex', 'smoker', 'region'], \n",
    "                              drop_first=True)\n",
    "\n",
    "print(df_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_processed['log_expenses'] = np.log(df_processed['expenses'])\n",
    "\n",
    "df_processed = df_processed.drop('expenses', axis=1)\n",
    "\n",
    "sns.histplot(df_processed['log_expenses'], kde=True, bins=30)\n",
    "plt.title('Distribution of Log-Transformed Medical expenses')\n",
    "plt.show()\n",
    "\n",
    "# When you make predictions later, they will be in \"log-dollars,\" \n",
    "# so you must transform them back using np.exp() to get the actual dollar amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_processed['log_expenses']\n",
    "\n",
    "X = df_processed.drop('log_expenses', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,     \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape (X): {X_train.shape}\")\n",
    "print(f\"Testing set shape (X): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "columns_to_scale = ['age', 'bmi', 'children']\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(X_train_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"✅ Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Model Parameters ---\")\n",
    "print(f\"Intercept (b): {model.intercept_:.4f}\")\n",
    "\n",
    "coefficients = pd.DataFrame(\n",
    "    data=model.coef_, \n",
    "    index=X.columns, \n",
    "    columns=['Coefficient']\n",
    ")\n",
    "\n",
    "coefficients['Abs_Coefficient'] = coefficients['Coefficient'].abs()\n",
    "print(\"\\nModel Coefficients (w):\")\n",
    "print(coefficients.sort_values(by='Abs_Coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n✅ Predictions made on train and test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(\"Test Set Performance:\")\n",
    "\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(f\"  R-squared (R²): {r2_test:.4f}\")\n",
    "\n",
    "y_test_orig = np.exp(y_test)\n",
    "y_pred_test_orig = np.exp(y_pred_test)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test_orig, y_pred_test_orig)\n",
    "print(f\"  Mean Absolute Error (MAE): ${mae_test:,.2f}\")\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_orig, y_pred_test_orig))\n",
    "print(f\"  Root Mean Squared Error (RMSE): ${rmse_test:,.2f}\")\n",
    "\n",
    "print(\"\\nTrain Set Performance (for comparison):\")\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(f\"  R-squared (R²): {r2_train:.4f}\")\n",
    "\n",
    "y_train_orig = np.exp(y_train)\n",
    "y_pred_train_orig = np.exp(y_pred_train)\n",
    "mae_train = mean_absolute_error(y_train_orig, y_pred_train_orig)\n",
    "print(f\"  Mean Absolute Error (MAE): ${mae_train:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test_orig, y=y_pred_test_orig, alpha=0.7)\n",
    "\n",
    "min_val = min(y_test_orig.min(), y_pred_test_orig.min())\n",
    "max_val = max(y_test_orig.max(), y_pred_test_orig.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "\n",
    "plt.xlabel(\"Actual expenses ($)\")\n",
    "plt.ylabel(\"Predicted expenses ($)\")\n",
    "plt.title(\"Actual vs. Predicted Medical expenses (Test Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Improving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "def evaluate_model(model_name, model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Makes predictions and prints evaluation metrics (R², MAE, RMSE).\n",
    "    Handles the inverse transform (np.exp) for error metrics.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluating Model: {model_name} ---\")\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"  R-squared (R²): {r2:.4f}\")\n",
    "    \n",
    "    y_test_orig = np.exp(y_test)\n",
    "    y_pred_orig = np.exp(y_pred)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "    \n",
    "    print(f\"  Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): ${rmse:,.2f}\\n\")\n",
    "    \n",
    "    return r2, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = {}\n",
    "\n",
    "baseline_pipe = Pipeline([\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "baseline_pipe.fit(X_train, y_train)\n",
    "r2, mae, rmse = evaluate_model(\"Baseline Linear Regression\", baseline_pipe, X_test, y_test)\n",
    "model_performance['Baseline_Linear'] = (r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Ridge (L2) Regularization Model...\")\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "    ('model', Ridge(alpha=1.0))  # alpha=1.0 is a common default to start with. A higher alpha = a stronger penalty / simpler model.\n",
    "])\n",
    "\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "r2, mae, rmse = evaluate_model(\"Ridge Regression (L2)\", ridge_pipe, X_test, y_test)\n",
    "model_performance['Ridge_L2'] = (r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Lasso (L1) Regularization Model...\")\n",
    "\n",
    "lasso_pipe = Pipeline([\n",
    "    ('model', Lasso(alpha=0.01))\n",
    "])\n",
    "\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "r2, mae, rmse = evaluate_model(\"Lasso Regression (L1)\", lasso_pipe, X_test, y_test)\n",
    "model_performance['Lasso_L1'] = (r2, mae)\n",
    "\n",
    "lasso_coefs = lasso_pipe.named_steps['model'].coef_\n",
    "\n",
    "coef_df = pd.DataFrame(\n",
    "    data=lasso_coefs, \n",
    "    index=X_train.columns, \n",
    "    columns=['Coefficient']\n",
    ")\n",
    "\n",
    "print(\"Lasso Coefficients:\")\n",
    "print(coef_df.sort_values(by='Coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Polynomial Regression Model...\")\n",
    "\n",
    "poly_pipe = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)), # 'degree=2' is standard. degree=3 or higher will likely overfit.\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "poly_pipe.fit(X_train, y_train)\n",
    "\n",
    "r2, mae, rmse = evaluate_model(\"Polynomial Regression (Degree 2)\", poly_pipe, X_test, y_test)\n",
    "model_performance['Polynomial_D2'] = (r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Polynomial + Ridge Regression Model...\")\n",
    "\n",
    "poly_ridge_pipe = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('model', Ridge(alpha=10.0)) # We use a stronger alpha to control the many new features\n",
    "])\n",
    "\n",
    "poly_ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "r2, mae, rmse = evaluate_model(\"Polynomial (D2) + Ridge (alpha=10)\", poly_ridge_pipe, X_test, y_test)\n",
    "model_performance['Poly_Ridge'] = (r2, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Final Model Comparison ---\")\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(\n",
    "    model_performance, \n",
    "    orient='index', \n",
    "    columns=['R_squared', 'Mean_Absolute_Error']\n",
    ")\n",
    "\n",
    "print(results_df.sort_values(by='R_squared', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
