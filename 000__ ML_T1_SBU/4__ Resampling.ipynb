{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Resampling Methods Lab\n",
    "\n",
    "This notebook covers the same content as the original ISLP Chapter 5 resampling lab, \n",
    "\n",
    "\n",
    "We will cover **exactly** the following topics:\n",
    "\n",
    "1. **Validation set approach** for polynomial regression:\n",
    "   - Predicting `mpg` from `horsepower` using polynomial models of degree 1–3 on the `Auto` dataset.\n",
    "2. **Cross-validation** for polynomial regression:\n",
    "   - Leave-One-Out Cross-Validation (LOOCV).\n",
    "   - 10-fold Cross-Validation.\n",
    "   - Using `ShuffleSplit` as a validation-set-like splitter.\n",
    "3. **Bootstrap**:\n",
    "   - Estimating the standard error of an `alpha` statistic on the `Portfolio` dataset.\n",
    "   - Estimating the standard error of regression coefficients (linear and quadratic models) for `mpg ~ horsepower` on the `Auto` dataset.\n",
    "   - Comparing bootstrap standard errors with the usual OLS standard errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Statsmodels for regression and standard OLS summaries\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ISLP provides the datasets (Auto, Portfolio)\n",
    "from ISLP import load_data\n",
    "\n",
    "# Scikit-learn for train/validation split and cross-validation helpers\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "We first define a few small helper functions:\n",
    "\n",
    "- `make_poly_features(x, degree)`: builds polynomial features of `x` up to a given degree (including the intercept column).\n",
    "- `mean_squared_error(y_true, y_pred)`: computes the MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_poly_features(x: np.ndarray, degree: int) -> np.ndarray:\n",
    "    x = np.asarray(x).reshape(-1, 1)  # ensure column vector\n",
    "    X_poly = [np.ones_like(x)]\n",
    "    for d in range(1, degree + 1):\n",
    "        X_poly.append(x ** d)\n",
    "    return np.hstack(X_poly)\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_poly_features(np.array([1,2,3]),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Validation Set Approach on the `Auto` Dataset\n",
    "\n",
    "We use the `Auto` dataset and treat `mpg` as the response and `horsepower` as the predictor.\n",
    "We will:\n",
    "\n",
    "1. Split the data into a **training set** and a **validation set**.\n",
    "2. Fit polynomial regression models of degree 1, 2, and 3 on the training set.\n",
    "3. Compute the **validation MSE** for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Auto dataset\n",
    "Auto = load_data('Auto')\n",
    "\n",
    "\n",
    "Auto = Auto.dropna()\n",
    "\n",
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    Auto,\n",
    "    test_size=196,\n",
    "    random_state=0  # fixed for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 3.1 Function to Fit a Polynomial Model and Compute Validation MSE\n",
    "\n",
    "We write a **clear and explicit function** that:\n",
    "\n",
    "- Takes the polynomial degree as input.\n",
    "- Builds polynomial features from `horsepower`.\n",
    "- Fits an OLS regression (using `statsmodels`) on the training data.\n",
    "- Predicts on the validation data.\n",
    "- Returns the validation MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_mse_for_degree(degree: int,\n",
    "                                train_df: pd.DataFrame,\n",
    "                                valid_df: pd.DataFrame,\n",
    "                                feature: str = 'horsepower',\n",
    "                                target: str = 'mpg') -> float:\n",
    "\n",
    "\n",
    "    # Extract training data\n",
    "    x_train = train_df[feature].values\n",
    "    y_train = train_df[target].values\n",
    "    \n",
    "    # Extract validation data\n",
    "    x_valid = valid_df[feature].values\n",
    "    y_valid = valid_df[target].values\n",
    "    \n",
    "    # Build polynomial feature matrices (including intercept)\n",
    "    X_train = make_poly_features(x_train, degree)\n",
    "    X_valid = make_poly_features(x_valid, degree)\n",
    "    \n",
    "    # Fit OLS model using statsmodels\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_valid = results.predict(X_valid)\n",
    "    \n",
    "    # Compute validation MSE\n",
    "    mse_valid = mean_squared_error(y_valid, y_pred_valid)\n",
    "    return mse_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 3.2 Validation MSE for Degrees 1, 2, and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1, 2, 3]\n",
    "validation_mse = {}\n",
    "\n",
    "for d in degrees:\n",
    "    mse = validation_mse_for_degree(d, train_df, valid_df)\n",
    "    validation_mse[d] = mse\n",
    "    print(f\"Degree {d}: validation MSE = {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation for Polynomial Regression\n",
    "\n",
    "Now we use the **full Auto dataset** and evaluate polynomial regression models using:\n",
    "\n",
    "1. **Leave-One-Out Cross-Validation (LOOCV)**.\n",
    "2. **10-fold Cross-Validation**.\n",
    "3. **ShuffleSplit** used as a train/validation splitter.\n",
    "\n",
    "Here we will use `sklearn`'s `LinearRegression` for the actual fitting inside CV,\n",
    "and our own `make_poly_features` for feature construction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 4.1 Helper Function: Cross-Validated MSE for a Given Degree\n",
    "\n",
    "We write a function that:\n",
    "\n",
    "- Builds polynomial features of a given degree for the entire dataset.\n",
    "- Performs cross-validation using a provided splitter (`KFold`, `LeaveOneOut`, etc.).\n",
    "- Returns the **average MSE** over the folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validated_mse_for_degree(degree: int,\n",
    "                                     df: pd.DataFrame,\n",
    "                                     feature: str = 'horsepower',\n",
    "                                     target: str = 'mpg',\n",
    "                                     splitter=None) -> float:\n",
    "\n",
    "\n",
    "    x = df[feature].values\n",
    "    y = df[target].values\n",
    "    \n",
    "    X = make_poly_features(x, degree)\n",
    "\n",
    "    # notice the intercept !\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    \n",
    "    mse_values = []\n",
    "    \n",
    "    for train_idx, test_idx in splitter.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    return float(np.mean(mse_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 4.2 LOOCV (Leave-One-Out Cross-Validation)\n",
    "\n",
    "We now evaluate polynomial degrees 1 through 5 using LOOCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv = LeaveOneOut()\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "loocv_mse = {}\n",
    "\n",
    "for d in degrees:\n",
    "    mse = cross_validated_mse_for_degree(d, Auto, splitter=loocv)\n",
    "    loocv_mse[d] = mse\n",
    "    print(f\"LOOCV - Degree {d}: MSE = {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 4.3 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "kfold_mse = {}\n",
    "for d in degrees:\n",
    "    mse = cross_validated_mse_for_degree(d, Auto, splitter=kfold)\n",
    "    kfold_mse[d] = mse\n",
    "    print(f\"10-fold CV - Degree {d}: MSE = {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 4.4 ShuffleSplit as a Validation-Set-Like Splitter\n",
    "\n",
    "We can also emulate the **validation set approach** using `ShuffleSplit`,\n",
    "which randomly splits the data into train/test multiple times.\n",
    "Here we use the same validation size as before, but let it shuffle multiple times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_split = ShuffleSplit(\n",
    "    n_splits=10,\n",
    "    test_size=196,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "shuffle_mse = {}\n",
    "d = 1\n",
    "\n",
    "mse_values = []\n",
    "x = Auto['horsepower'].values\n",
    "y = Auto['mpg'].values\n",
    "X = make_poly_features(x, d)\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "for train_idx, test_idx in shuffle_split.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse_values.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "shuffle_mse[d] = float(np.mean(mse_values))\n",
    "print(f\"ShuffleSplit (10 splits) - Degree {d}: average MSE = {shuffle_mse[d]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 5. Bootstrap on the `Portfolio` Dataset: Estimating the Standard Error of α\n",
    "\n",
    "We now switch to the `Portfolio` dataset, which contains returns for two assets `X` and `Y`.\n",
    "We define a statistic α that depends on the covariance matrix of `X` and `Y`:\n",
    "\n",
    "\\begin{align}\n",
    "\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}.\n",
    "\\end{align}\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Define a function to compute α from a given sample.\n",
    "2. Implement a generic bootstrap function to estimate the **standard error** of any statistic.\n",
    "3. Apply it to α.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Portfolio dataset\n",
    "Portfolio = load_data('Portfolio')\n",
    "Portfolio = Portfolio.dropna()\n",
    "\n",
    "Portfolio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 5.1 Statistic Function for α\n",
    "\n",
    "The function `alpha_statistic(data, indices)`:\n",
    "\n",
    "- Selects a bootstrap sample using the given indices.\n",
    "- Computes the covariance matrix of `X` and `Y`.\n",
    "- Returns α.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_statistic(data: pd.DataFrame, indices: np.ndarray) -> float:\n",
    "\n",
    "    sample = data.iloc[indices]\n",
    "    cov_matrix = np.cov(sample[['X', 'Y']].values, rowvar=False)\n",
    "    \n",
    "    sigma_x2 = cov_matrix[0, 0]\n",
    "    sigma_y2 = cov_matrix[1, 1]\n",
    "    sigma_xy = cov_matrix[0, 1]\n",
    "    \n",
    "    alpha = (sigma_y2 - sigma_xy) / (sigma_x2 + sigma_y2 - 2 * sigma_xy)\n",
    "    return float(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### 5.2 Generic Bootstrap Standard Error Function\n",
    "\n",
    "We now implement a reusable function:\n",
    "\n",
    "`bootstrap_standard_error(stat_func, data, B, random_state)`\n",
    "\n",
    "that:\n",
    "\n",
    "1. Draws `B` bootstrap samples (with replacement).\n",
    "2. Computes the statistic each time.\n",
    "3. Returns the estimated standard deviation of the statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_standard_error(stat_func,\n",
    "                             data: pd.DataFrame,\n",
    "                             B: int = 1000,\n",
    "                             random_state: int = 0) -> float:\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(data)\n",
    "    \n",
    "    values = []\n",
    "    for _ in range(B):\n",
    "\n",
    "        sample_indices = rng.choice(n, size=n, replace=True)\n",
    "        value = stat_func(data, sample_indices)\n",
    "        values.append(value)\n",
    "    \n",
    "    values = np.asarray(values)\n",
    "\n",
    "    return values.std(axis=0, ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 5.3 Bootstrap Standard Error for α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_se = bootstrap_standard_error(alpha_statistic,\n",
    "                                           Portfolio,\n",
    "                                           B=1000,\n",
    "                                           random_state=0)\n",
    "print(f\"Bootstrap SE for alpha: {alpha_se:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## 6. Bootstrap Standard Errors for Regression Coefficients in `Auto`\n",
    "\n",
    "Now we return to the `Auto` dataset and estimate **bootstrap standard errors** for the coefficients\n",
    "of:\n",
    "\n",
    "1. A **linear model**: `mpg ~ horsepower` (degree 1).\n",
    "2. A **quadratic model**: `mpg ~ horsepower + horsepower^2` (degree 2).\n",
    "\n",
    "We then compare these bootstrap SEs to the standard OLS SEs provided by `statsmodels`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### 6.1 Helper Function: Fit OLS on a Bootstrap Sample and Return Coefficients\n",
    "\n",
    "We define a statistic function:\n",
    "\n",
    "`ols_coefficients_statistic(data, indices, degree)`\n",
    "\n",
    "that:\n",
    "\n",
    "- Selects a bootstrap sample by `indices`.\n",
    "- Builds polynomial features of the chosen degree.\n",
    "- Fits an OLS regression using `statsmodels`.\n",
    "- Returns the fitted coefficient vector (intercept and slopes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_coefficients_statistic(data: pd.DataFrame,\n",
    "                               indices: np.ndarray,\n",
    "                               degree: int,\n",
    "                               feature: str = 'horsepower',\n",
    "                               target: str = 'mpg') -> np.ndarray:\n",
    "\n",
    "    sample = data.iloc[indices]\n",
    "    \n",
    "    x = sample[feature].values\n",
    "    y = sample[target].values\n",
    "    \n",
    "    X = make_poly_features(x, degree)\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    return results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### 6.2 Bootstrap SE for the Linear Model (`degree = 1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_coefficients_statistic(data: pd.DataFrame,\n",
    "                                  indices: np.ndarray) -> np.ndarray:\n",
    "    return ols_coefficients_statistic(data, indices, degree=1)\n",
    "\n",
    "\n",
    "linear_se = bootstrap_standard_error(linear_coefficients_statistic,\n",
    "                                     Auto,\n",
    "                                     B=1000,\n",
    "                                     random_state=1)\n",
    "print(\"Bootstrap SE for linear model coefficients (intercept, slope):\")\n",
    "print(linear_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### 6.3 Bootstrap SE for the Quadratic Model (`degree = 2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_coefficients_statistic(data: pd.DataFrame,\n",
    "                                     indices: np.ndarray) -> np.ndarray:\n",
    "    return ols_coefficients_statistic(data, indices, degree=2)\n",
    "\n",
    "\n",
    "quadratic_se = bootstrap_standard_error(quadratic_coefficients_statistic,\n",
    "                                         Auto,\n",
    "                                         B=1000,\n",
    "                                         random_state=2)\n",
    "print(\"Bootstrap SE for quadratic model coefficients (intercept, beta1, beta2):\")\n",
    "print(quadratic_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### 6.4 Comparison with Standard OLS SEs\n",
    "\n",
    "We now fit the same models on the **full dataset** and compare:\n",
    "\n",
    "- Bootstrap SEs.\n",
    "- Conventional OLS SEs from `statsmodels`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model OLS SEs\n",
    "x = Auto['horsepower'].values\n",
    "y = Auto['mpg'].values\n",
    "\n",
    "X_lin = make_poly_features(x, degree=1)\n",
    "model_lin = sm.OLS(y, X_lin)\n",
    "results_lin = model_lin.fit()\n",
    "print(\"OLS SEs for linear model coefficients (intercept, slope):\")\n",
    "print(results_lin.bse)\n",
    "\n",
    "# Quadratic model OLS SEs\n",
    "X_quad = make_poly_features(x, degree=2)\n",
    "model_quad = sm.OLS(y, X_quad)\n",
    "results_quad = model_quad.fit()\n",
    "print(\"\\nOLS SEs for quadratic model coefficients (intercept, beta1, beta2):\")\n",
    "print(results_quad.bse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
