{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## PyCaret: The Low-Code Machine Learning Framework\n",
    "\n",
    "### 1. What is PyCaret?\n",
    "**PyCaret** is an open-source, low-code machine learning library in Python that automates machine learning workflows. It is an end-to-end machine learning and model management tool that exponentially speeds up the experiment cycle and makes you more productive.\n",
    "\n",
    "In comparison to other open-source machine learning libraries, PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with only a few words. This makes experiments exponentially fast and efficient.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why PyCaret for Data Science?\n",
    "* **Productivity:** It allows you to go from raw data to a deployed model in minutes.\n",
    "* **Ease of Use:** It features a simple and consistent syntax across all modules.\n",
    "* **Business Ready:** Designed for fast prototyping and production-grade deployments.\n",
    "* **Automatic Preprocessing:** It automatically handles missing values, categorical encoding, feature scaling, and train-test splits during the `setup()` phase.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Core Modules and Use Cases\n",
    "PyCaret is modular. Each module is designed for a specific machine learning task:\n",
    "\n",
    "| Module | Purpose | Real-World Example |\n",
    "| :--- | :--- | :--- |\n",
    "| **Classification** | Predict categorical labels | Customer Churn, Spam Detection |\n",
    "| **Regression** | Predict continuous values | House Prices, Stock Value |\n",
    "| **Clustering** | Group similar data points | Customer Segmentation |\n",
    "| **Anomaly Detection** | Identify rare events | Fraud Detection, System Failures |\n",
    "| **Time Series** | Forecasting based on time | Sales Forecasting, Weather Prediction |\n",
    "| **NLP** | Topic Modeling | Text Theme Extraction |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. The Standard Workflow\n",
    "Every PyCaret experiment follows these standardized functional steps:\n",
    "\n",
    "1.  **`setup()`**: Initializes the experiment and the transformation pipeline.\n",
    "2.  **`compare_models()`**: Trains all models in the library and ranks them by performance.\n",
    "3.  **`create_model()`**: Trains a specific algorithm for deeper analysis.\n",
    "4.  **`tune_model()`**: Automatically optimizes the hyperparameters of a model.\n",
    "5.  **`plot_model()`**: Generates interactive performance visualizations (ROC, Residuals, etc.).\n",
    "6.  **`finalize_model()`**: Trains the model on the complete dataset for production.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create Output directory for model storage\n",
    "output_dir = './Output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 1️⃣ PyCaret Regression: From Data to Deployment\n",
    "Regression is a Supervised Learning task used to predict **continuous numerical outcomes**. \n",
    "In this notebook, we use the **Boston Housing Dataset** to predict house prices (`medv`).\n",
    "\n",
    "## Key Learning Objectives:\n",
    "1. **Automated Setup:** Handling missing data and feature engineering.\n",
    "2. **Benchmark Comparison:** Ranking 20+ algorithms instantly.\n",
    "3. **Interactive Evaluation:** Using dashboards for error analysis.\n",
    "4. **Model Persistence:** Saving and loading models for production.\n",
    "\n",
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 1. Initializing the Experiment\n",
    "The `setup()` function is the engine of PyCaret. It creates a transformation pipeline that \n",
    "ensures your data is clean and ready for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('./Data/Boston.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize setup\n",
    "# target: 'medv' (Median House Value)\n",
    "# session_id: For reproducibility\n",
    "# log_experiment: Set to True if you want to track experiments\n",
    "reg_setup = setup(data=df, target='medv', session_id=123, verbose=False)\n",
    "\n",
    "print(\"✅ Pipeline Setup Complete: Data is now cleaned and split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 2. Comparing and Fine-Tuning Models\n",
    "We first find the best base model, then we use `tune_model()` to automatically optimize its \n",
    "hyperparameters for even better $R^2$ scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models and pick the best one\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Fine-tune the best model to squeeze out more performance\n",
    "tuned_model = tune_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 3. Visual Analysis\n",
    "PyCaret provides an interactive dashboard through `evaluate_model()`. \n",
    "You can inspect:\n",
    "- **Residuals:** To check for non-linear patterns in errors.\n",
    "- **Feature Importance:** To see which variables (like 'RM' - rooms) impact the price most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This opens an interactive GUI within the notebook\n",
    "evaluate_model(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 4. Predicting and Finalizing\n",
    "`predict_model()` shows how the model performs on the hold-out set. \n",
    "`finalize_model()` then trains it on 100% of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance on test data\n",
    "holdout_predictions = predict_model(tuned_model)\n",
    "\n",
    "# Finalize the model for saving\n",
    "final_reg_model = finalize_model(tuned_model)\n",
    "\n",
    "print(\"--- Sample Predictions ---\")\n",
    "print(holdout_predictions[['medv', 'prediction_label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 5. Saving and Re-loading the Model\n",
    "To use this model in a real application, we save it as a `.pkl` file and demonstrate how to load it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(output_dir, 'regression_boston_house_model')\n",
    "save_model(final_reg_model, save_path)\n",
    "\n",
    "# --- RE-LOADING THE MODEL ---\n",
    "# Load the saved model (pretending we are in a new script)\n",
    "loaded_house_model = load_model(save_path)\n",
    "\n",
    "# Predict on new data using the loaded model\n",
    "new_data = df.head(5) # Taking 5 rows as \"new\" data\n",
    "final_preds = predict_model(loaded_house_model, data=new_data)\n",
    "\n",
    "print(\"\\n✅ Predictions from LOADED model:\")\n",
    "print(final_preds[['prediction_label']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
