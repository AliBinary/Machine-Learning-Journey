{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 2️⃣ PyCaret Classification: Predicting Survival on the Titanic\n",
    "Classification is a Supervised Learning task where the goal is to predict **categorical labels** (discrete classes). \n",
    "In this notebook, we aim to predict whether a passenger survived (`1`) or not (`0`).\n",
    "\n",
    "## Key Learning Objectives:\n",
    "1. **Automated Preprocessing**: Handling categorical variables like 'Sex' and 'Embarked'.\n",
    "2. **Model Leaderboard**: Comparing classifiers (Random Forest, XGBoost, CatBoost, etc.).\n",
    "3. **Performance Metrics**: Analyzing Accuracy, AUC, Precision, and Recall.\n",
    "4. **Model Deployment**: Exporting and re-loading the classification pipeline.\n",
    "\n",
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "import os\n",
    "\n",
    "# Create Output folder\n",
    "output_dir = './Output'\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Initializing the Experiment\n",
    "PyCaret's `setup()` function automatically detects feature types and handles missing values (Imputation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/Titanic-Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize setup\n",
    "# target: 'Survived' (0 = No, 1 = Yes)\n",
    "# session_id: For reproducibility\n",
    "# fix_imbalance: Useful if one class has much fewer samples than the other\n",
    "clf_setup = setup(data=df, target='Survived', session_id=42, verbose=False)\n",
    "\n",
    "print(\"✅ Classification Setup Complete: Pipeline is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2. Comparing and Fine-Tuning Models\n",
    "We compare all available classifiers and then use `tune_model()` to optimize the **F1-Score**, which balances Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models and return the best one based on Accuracy\n",
    "best_clf_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the best model to optimize for balanced performance\n",
    "tuned_clf_model = tune_model(best_clf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3. Visual Analysis & Performance Metrics\n",
    "In Classification, we use the **Confusion Matrix** to see exactly where the model is making mistakes.\n",
    "- **True Positives**: Correctly predicted survivors.\n",
    "- **False Positives**: Passengers predicted to survive who unfortunately didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the interactive evaluation dashboard\n",
    "evaluate_model(tuned_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifically plot the Confusion Matrix\n",
    "plot_model(tuned_clf_model, plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifically plot the ROC Curve\n",
    "plot_model(tuned_clf_model, plot='auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 4. Finalizing the Model\n",
    "We check the performance on the test set and then finalize the model for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on hold-out/test data\n",
    "classification_results = predict_model(tuned_clf_model)\n",
    "\n",
    "# Finalize the model (train on 100% of data)\n",
    "final_titanic_model = finalize_model(tuned_clf_model)\n",
    "\n",
    "print(\"--- Sample Predictions (Survived vs. Prediction_Label) ---\")\n",
    "print(classification_results[['Survived', 'prediction_label', 'prediction_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 5. Model Export and Re-use\n",
    "We save the classification pipeline as a `.pkl` file to use it in future applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "clf_save_path = os.path.join(output_dir, 'classification_titanic_survival_model')\n",
    "save_model(final_titanic_model, clf_save_path)\n",
    "\n",
    "# --- RE-LOADING THE MODEL ---\n",
    "# Load the saved pipeline\n",
    "loaded_survival_model = load_model(clf_save_path)\n",
    "\n",
    "# Predict on new data (first 5 rows for demo)\n",
    "new_passengers = df.head(5)\n",
    "final_preds = predict_model(loaded_survival_model, data=new_passengers)\n",
    "\n",
    "print(\"\\n✅ Predictions from LOADED Classification model:\")\n",
    "print(final_preds[['prediction_label', 'prediction_score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
