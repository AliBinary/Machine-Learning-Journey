{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1 align=\"center\">SHAP Values</h1>\n",
    "    <h3 align=\"center\">SHAP (SHapley Additive exPlanations)</h3>\n",
    "    <h4 align=\"center\"><a href=\"http://www.iran-machinelearning.ir\">Soheil Tehranipour</a></h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_header.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is SHAP Analysis?\n",
    "\n",
    "If you Google ‘SHAP analysis’, you will find that the term comes from a 2017 paper by Lundberg and Lee, called “A Unified Approach to Interpreting Model Predictions”, which introduces the concept of SHapley Additive exPlanations (SHAP). The goal of SHAP is to explain a machine learning model’s prediction by calculating the contribution of each feature to the prediction.\n",
    "\n",
    "The technical explanation is that it does this by computing Shapley values from coalitional game theory. Of course, if you’re unfamiliar with game theory and data science, that may not mean much to you. Simply put, Shapely values is a method for showing the relative impact of each feature (or variable) we are measuring on the eventual output of the machine learning model by comparing the relative effect of the inputs against the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Analysis Explained\n",
    "Think of buying a second-hand car: You have a particular make and model in mind and a quick search online shows a variety of prices and conditions. In terms of coalitional game theory, the “game” is predicting the price of a specific car. The prediction will have a combination of features, called a “coalition”. The “gain” is the difference between the predicted price for a car against the average predicted price for all combinations of features. The “players” are the feature values that you input into the model which work together to create the gain (or difference from the average value).\n",
    "\n",
    "Say the average price of your desired car is $20,000. Several factors will move that price up or down for a given vehicle. Age, trim level, condition, and mileage will all influence the price on the vehicle. That’s why it can be difficult to tell if a specific car is priced properly above or below market given all the variables.\n",
    "\n",
    "Machine learning can solve this problem by building a model to predict what the price should be for a specific vehicle, taking all the variables into account. A SHAP analysis of that model will give you an indication of how significant each factor is in determining the final price prediction the model outputs. It does this by running a large number of predictions comparing the impact of a variable against the other features.\n",
    "\n",
    "In our example, it’s easy to see that if I look the prices of cars with varying mileage but the same model year, condition and trim level, I can ascertain the impact of mileage on the overall price. SHAP is a bit more complicated since the analysis runs against the varying ‘coalitions’ or combinations of the other variables to get an average impact of the mileage of the car against all possible combinations of features.\n",
    "\n",
    "In our example, we would end up running a machine learning model varying mileage against all the possible combinations of trim level, model year and condition. Obviously, this means running a lot of combinations through the machine learning model, as the number of combinations grows exponentially with the number of variables you are looking at.\n",
    "\n",
    "In the used car case, we would have the following coalitions:\n",
    "\n",
    "    Trim Level\n",
    "    Mileage\n",
    "    Model Year\n",
    "    Condition\n",
    "    Trim Level + Mileage\n",
    "    Trim Level + Model Year\n",
    "    Trim Level + Condition\n",
    "    Mileage + Model Year\n",
    "    Mileage + Condition\n",
    "    Trim Level + Mileage + Model Year\n",
    "    Trim Level + Model Year + Condition\n",
    "    Mileage + Trim Level + Condition\n",
    "    Mileage + Model Year + Condition\n",
    "    Mileage + Trim Level + Model Year + Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shap.datasets.boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean value of median house prices (in $ thousand): {round(y.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catagorical_features = ['CHAS']\n",
    "numerical_features = [c for c in X_train.columns if c not in catagorical_features]\n",
    "cat = [([c], [OrdinalEncoder()]) for c in catagorical_features]\n",
    "num = [([n], [SimpleImputer(), StandardScaler()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num + cat, df_out=True)\n",
    "preprocessed_X_train = mapper.fit_transform(X_train)\n",
    "preprocessed_X_train = sm.add_constant(preprocessed_X_train)\n",
    "reg = sm.OLS(y_train, preprocessed_X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y, mapper=None, reg=None, transform=False):\n",
    "    if transform:\n",
    "        X = mapper.transform(X)\n",
    "        X = sm.add_constant(X, has_constant='add') \n",
    "    y_pred = reg.predict(X)\n",
    "    return mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = evaluate(X_train, y_train, mapper, reg, True)\n",
    "test_mae = evaluate(X_test, y_test, mapper, reg, True)\n",
    "print(f\"train MAE = {round(train_mae, 3)}, test MAE = {round(test_mae, 3)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "catagorical_features = ['CHAS']\n",
    "numerical_features = [c for c in X_train.columns if c not in catagorical_features]\n",
    "cat = [([c], [OrdinalEncoder()]) for c in catagorical_features]\n",
    "num = [([n], [SimpleImputer(), StandardScaler()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num + cat, df_out=True)\n",
    "reg = RandomForestRegressor()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('reg', reg)\n",
    "])\n",
    "p = pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_mae = evaluate(X_train, y_train, reg=pipeline)\n",
    "test_mae = evaluate(X_test, y_test, reg=pipeline)\n",
    "print(f\"train MAE = {round(train_mae, 3)}, test MAE = {round(test_mae, 3)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = reg.feature_importances_.argsort()\n",
    "features = numerical_features + catagorical_features \n",
    "result = sorted(zip(features, reg.feature_importances_), key = lambda x: x[1], reverse=False)\n",
    "plt.barh([x[0] for x in result], [x[1] for x in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "preprocessed_X_train = mapper.fit_transform(X_train)\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "hidden_size = 32\n",
    "batch_size = 50\n",
    "input_dim = preprocessed_X_train.shape[1]\n",
    "batch_no = preprocessed_X_train.shape[0] // batch_size\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_size),\n",
    "    nn.Linear(hidden_size, 1)\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        x_batch = Variable(torch.FloatTensor(preprocessed_X_train.values[start:end]))\n",
    "        y_batch = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "        optimizer.zero_grad()\n",
    "        y_preds = model(x_batch)\n",
    "        loss = criterion(y_preds, torch.unsqueeze(y_batch,dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if epoch % 10 == 0: \n",
    "        print(\"Epoch {}, Loss: {}\".format(epoch, running_loss))\n",
    "        \n",
    "preprocessed_X_test = mapper.transform(X_test)\n",
    "y_pred = model(torch.from_numpy(preprocessed_X_test.values).float()).flatten().detach().numpy()\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "preprocessed_X_train = mapper.transform(X_train)\n",
    "y_pred = model(torch.from_numpy(preprocessed_X_train.values).float()).flatten().detach().numpy()\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "print(f\"\\ntrain MAE = {round(train_mae, 3)}, test MAE = {round(test_mae, 3)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have a direct way to identify feature importance for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with Interpretation\n",
    "- No specific method to define feature importance that is model agnostic\n",
    "- For a given sample, why does the prediction have that value?\n",
    "\n",
    "Answer: Shap values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition of Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we think about answering the question \"Why is the output for this specific sample so low/high\" manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False) #revert\n",
    "catagorical_features = ['CHAS']\n",
    "numerical_features = [c for c in X_train.columns if c not in catagorical_features]\n",
    "cat = [([c], [SimpleImputer(strategy='constant', fill_value=0),\n",
    "              OrdinalEncoder()]) for c in catagorical_features]\n",
    "num = [([n], [SimpleImputer(), StandardScaler()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num + cat, df_out=True)\n",
    "reg = LinearRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('reg', reg)\n",
    "])\n",
    "p = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_frame = pd.DataFrame(columns=catagorical_features+numerical_features, index=[0])\n",
    "nan_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_value = round(pipeline.predict(nan_frame)[0], 3)\n",
    "print(f\"Expected value of the output (base value): {base_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[0: 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prediction = round(pipeline.predict(X_test.iloc[0: 1])[0], 3)\n",
    "print(f\"Current Prediction: {sample_prediction}, Actual value: {y_test[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How did we get from 22.767 to 15.851?**\n",
    "- Find this by adjusting individual feature values. But this can be hard to look at\n",
    "- Fast way to visualize is with Partial Dependency Plots (which uses Shap values for individual samples)\n",
    "- Shap values assign a contributing factor to every feature of every sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(pipeline.predict, X_train)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_dependence_plot(feature, idx=None):\n",
    "    if idx is None: # visualize all samples\n",
    "        shap.plots.partial_dependence(\n",
    "            feature,\n",
    "            pipeline.predict,\n",
    "            X_train, \n",
    "            ice=False,\n",
    "            model_expected_value=True, \n",
    "            feature_expected_value=True)\n",
    "    else: # visualize sample idx\n",
    "        shap.partial_dependence_plot(\n",
    "            feature, \n",
    "            pipeline.predict,\n",
    "            X_train, \n",
    "            ice=False,\n",
    "            model_expected_value=True, \n",
    "            feature_expected_value=True,\n",
    "            shap_values=shap_values[idx:idx+1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_dependence_plot('CRIM', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_dependence_plot('RAD', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_dependence_plot('AGE', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to look at every feature for every sample. So lets look at all features of the same sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_feature_importance(idx, type='condensed'):\n",
    "    if type == 'condensed':\n",
    "        return shap.plots.force(shap_values[idx])\n",
    "    elif type == 'waterfall':\n",
    "        return shap.plots.waterfall(shap_values[idx])\n",
    "    else:\n",
    "        return \"Return valid visual ('condensed', 'waterfall')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_feature_importance(0, 'waterfall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_feature_importance(0, 'condensed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at individual samples can be a bother. Let's look at all samples together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two most important features according to the LinearRegression model:\n",
    "- RAD: index of accessibility to radial highways\n",
    "- TAX: full-value property-tax rate per $10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values.values, X_train, plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret the neural network model in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_X_train = mapper.fit_transform(X_train)\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "hidden_size = 32\n",
    "batch_size = 50\n",
    "input_dim = preprocessed_X_train.shape[1]\n",
    "batch_no = preprocessed_X_train.shape[0] // batch_size\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_size),\n",
    "    nn.Linear(hidden_size, 1)\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        x_batch = Variable(torch.FloatTensor(preprocessed_X_train.values[start:end]))\n",
    "        y_batch = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "        optimizer.zero_grad()\n",
    "        y_preds = model(x_batch)\n",
    "        loss = criterion(y_preds, torch.unsqueeze(y_batch,dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if epoch % 10 == 0: \n",
    "        print(\"Epoch {}, Loss: {}\".format(epoch, running_loss))\n",
    "        \n",
    "preprocessed_X_test = mapper.transform(X_test)\n",
    "y_pred = model(torch.from_numpy(preprocessed_X_test.values).float()).flatten().detach().numpy()\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "preprocessed_X_train = mapper.transform(X_train)\n",
    "y_pred = model(torch.from_numpy(preprocessed_X_train.values).float()).flatten().detach().numpy()\n",
    "train_mae = mean_absolute_error(y_train, y_pred)\n",
    "print(f\"\\ntrain MAE = {round(train_mae, 3)}, test MAE = {round(test_mae, 3)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model, torch.from_numpy(preprocessed_X_train.values).float())\n",
    "shap_values = explainer.shap_values(torch.from_numpy(preprocessed_X_test.values).float())\n",
    "shap.summary_plot(shap_values, X_test, plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important features for this neural network:\n",
    "- DIS: weighted distances to five Boston employment centres\n",
    "- RAD: index of accessibility to radial highways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://github.com/slundberg/shap\n",
    "2. https://acerta.ai/blog/understanding-machine-learning-with-shap-analysis/\n",
    "3. https://towardsdatascience.com/introduction-to-shap-values-and-their-application-in-machine-learning-8003718e6827\n",
    "4. https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail\n",
    "5. https://arxiv.org/pdf/1705.07874.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
